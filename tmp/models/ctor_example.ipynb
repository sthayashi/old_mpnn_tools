{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('/mnt/projects/sne_students/M.Thesis_Scott/git_repos/GNN_MBTR_MD/graphNN_tools/')\n",
    "import gnn_tools as gnn\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Dataset\n",
    ""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.nn import NNConv, GATConv, Set2Set\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.nn import (graclus, max_pool, max_pool_x,\n",
    "                                global_mean_pool)\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU, LeakyReLU, GRU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops,add_remaining_self_loops\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from inits import reset, uniform\n",
    "\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import BatchNorm1d as BN\n",
    "from torch.nn import LayerNorm as LN\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "from pathlib import Path\n",
    ""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "class transferIntegral(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(transferIntegral, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['processed_data.dataset']\n",
    "    def download(self):\n",
    "        pass\n",
    "    def process(self):\n",
    "        pass\n",
    ""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        '''\n",
    "        nn (torch.nn.Module) \u2013 A neural network \u210e\ud835\udeaf that maps edge features\n",
    "        edge_attr of shape [-1, num_edge_features] to\n",
    "        shape [-1, in_channels * out_channels], e.g.,\n",
    "        defined by torch.nn.Sequential.\n",
    "        '''\n",
    "        # number of neurons in dense nn\n",
    "        p1 = 28\n",
    "        p2 = 28\n",
    "        # get features from dataset, but hardcode this for now\n",
    "#       nbr_node_features = dataset[0].x.size()[1]\n",
    "#       nbr_edge_features = dataset[0].edge_attr.size()[1]\n",
    "        nbr_node_features = 2\n",
    "        nbr_edge_features = 1\n",
    "\n",
    "        totNbrFeatures = 0\n",
    "        totNbrFeatures += p2*2\n",
    "\n",
    "        self.lin0 = torch.nn.Linear(nbr_node_features, p2, bias = False)\n",
    "        self.BN0 = BN(round(p2))\n",
    "\n",
    "        nn = Seq(Linear(nbr_edge_features, p1, bias = False), BN(p1), LeakyReLU(), Linear(p1, p2 * p2, bias = False), BN(p2 * p2))\n",
    "\n",
    "        self.conv = NNConv(p2, p2,nn, aggr='mean')\n",
    "\n",
    "        self.set2set = Set2Set(p2, processing_steps=3)\n",
    "        self.gru = GRU(p2, p2)\n",
    "\n",
    "        print(\"totNbrFeatures\", totNbrFeatures)\n",
    "        self.lin1 = torch.nn.Linear(totNbrFeatures, round(totNbrFeatures/2))\n",
    "        self.lin2 = torch.nn.Linear(round(totNbrFeatures/2), round(totNbrFeatures/4))\n",
    "        self.lin_final = torch.nn.Linear(round(totNbrFeatures/4), 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        y = None\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        out = F.leaky_relu(self.BN0(self.lin0(x)))\n",
    "        h = out.unsqueeze(0)\n",
    "\n",
    "        for i in range(3):\n",
    "            m = F.leaky_relu(self.conv(out, edge_index, edge_attr))\n",
    "            out, h = self.gru(m.unsqueeze(0), h)\n",
    "            out = out.squeeze(0)\n",
    "\n",
    "        y_gnn = self.set2set(out, batch)\n",
    "        y = y_gnn\n",
    "\n",
    "        y = F.dropout(y, p = 0.5, training=self.training)\n",
    "        y = F.leaky_relu(self.lin1(y))\n",
    "        y = F.leaky_relu(self.lin2(y))\n",
    "        y = self.lin_final(y)\n",
    "        y = y.squeeze(-1)\n",
    "        return y\n",
    ""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "dataset = transferIntegral(root='data')\n",
    "print(len(dataset))\n",
    "print(\"Node features: {}\".format(dataset[0].x))\n",
    "print(\"Edge attributes: {}\".format(dataset[0].edge_attr))\n",
    "print(\"Tranfer integral: {}\".format(dataset[0].y))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48818\nNode features: tensor([[1., 1.],\n        [1., 1.],\n        [1., 1.],\n        [1., 9.],\n        [1., 6.],\n        [1., 6.],\n        [1., 8.],\n        [1., 6.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 1.],\n        [1., 6.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 1.],\n        [1., 6.],\n        [1., 9.],\n        [1., 9.],\n        [1., 6.],\n        [1., 1.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 1.],\n        [1., 6.],\n        [1., 9.],\n        [1., 9.],\n        [1., 9.],\n        [2., 8.],\n        [2., 8.]])\nEdge attributes: tensor([[-0.5907],\n        [-0.5907],\n        [-0.4019],\n        ...,\n        [-0.2276],\n        [-0.1969],\n        [ 3.7561]])\nTranfer integral: tensor([-2.7547])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
